{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results\n",
    "results = pd.read_csv(\"../data/final_eval_set.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svm_match\n",
       "False    0.609\n",
       "True     0.391\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model by model, check the accuracy (match rate)\n",
    "results.groupby('svm_match').size().transform(lambda x: round(x/sum(x),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_match\n",
       "False    0.6\n",
       "True     0.4\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby('log_match').size().transform(lambda x: round(x/sum(x),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bert_match\n",
       "False    0.599\n",
       "True     0.401\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby('bert_match').size().transform(lambda x: round(x/sum(x),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true  bert_match\n",
       "0     False         0.561386\n",
       "      True          0.438614\n",
       "1     False         0.553089\n",
       "      True          0.446911\n",
       "2     False         0.683863\n",
       "      True          0.316137\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model by model, check the accuracy by true category (0 = good, 1 = controversial, 2 = bad)\n",
    "# https://stackoverflow.com/questions/23377108/pandas-percentage-of-total-with-groupby\n",
    "results.groupby(['true', 'bert_match']).size().groupby(level=0).apply(lambda x: x / float(x.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true  svm_match\n",
       "0     False        0.591337\n",
       "      True         0.408663\n",
       "1     False        0.675973\n",
       "      True         0.324027\n",
       "2     False        0.554034\n",
       "      True         0.445966\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby(['true', 'svm_match']).size().groupby(level=0).apply(lambda x: x / float(x.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true  log_match\n",
       "0     False        0.584406\n",
       "      True         0.415594\n",
       "1     False        0.657666\n",
       "      True         0.342334\n",
       "2     False        0.552812\n",
       "      True         0.447188\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby(['true', 'log_match']).size().groupby(level=0).apply(lambda x: x / float(x.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare relative performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n",
       "0    0.323\n",
       "1    0.350\n",
       "2    0.327\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check actual label distribution - it is relatively even but a little more controversial\n",
    "results.groupby('true').size().transform(lambda x: round(x/sum(x),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model by model, check the cases where it \"wins\" i.e. where that model is correct and the others are wrong\n",
    "\n",
    "bert_wins = results[(results['svm_match'] == False) & (results['log_match'] == False) & (results['bert_match'] == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1995"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n",
       "0    0.314\n",
       "1    0.512\n",
       "2    0.174\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_wins.groupby('true').size().transform(lambda x: round(x/sum(x),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n",
       "0    0.288\n",
       "1    0.322\n",
       "2    0.390\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_wins = results[(results['svm_match'] == True) & (results['log_match'] == False) & (results['bert_match'] == False)]\n",
    "svm_wins.groupby('true').size().transform(lambda x: round(x/sum(x),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svm_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n",
       "0    0.254\n",
       "1    0.356\n",
       "2    0.389\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_wins = results[(results['svm_match'] == False) & (results['log_match'] == True) & (results['bert_match'] == False)]\n",
    "log_wins.groupby('true').size().transform(lambda x: round(x/sum(x),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(log_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agree_win = results[(results['svm_match'] == True) & (results['log_match'] == True) & (results['bert_match'] == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n",
       "0    0.400\n",
       "1    0.257\n",
       "2    0.343\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_agree_win.groupby('true').size().transform(lambda x: round(x/sum(x),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agree_lose = results[(results['svm_match'] == False) & (results['log_match'] == False) & (results['bert_match'] == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n",
       "0    0.319\n",
       "1    0.332\n",
       "2    0.349\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_agree_lose.groupby('true').size().transform(lambda x: round(x/sum(x),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
