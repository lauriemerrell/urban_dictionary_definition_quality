{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "# Following work I submitted in HW3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv(\"../data/svm_data/train.csv\")\n",
    "test = pd.read_csv(\"../data/svm_data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['defn']\n",
    "y_train = train['cat']\n",
    "X_test = test['defn']\n",
    "y_test = test['cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic comparison loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: max_df = 1.0 min_df = 1 lower = True\n",
      "Count vectorizing at 2020-11-22 12:44:36.390843\n",
      "TF-IDF vectorizing at 2020-11-22 12:44:56.463881\n",
      "Fitting TF-IDF count SVM at 2020-11-22 12:44:58.065212\n",
      "Evaluating TF-IDF SVM at 2020-11-22 12:53:15.500618\n",
      "('tfidf', 1.0, 1, True, 314448, 0.551372681132607, 0.5512513477651412, 0.4040835261695817, 0.4038787504594819)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 1.0 min_df = 1 lower = False\n",
      "Count vectorizing at 2020-11-22 12:53:26.104429\n",
      "TF-IDF vectorizing at 2020-11-22 12:53:47.326347\n",
      "Fitting TF-IDF count SVM at 2020-11-22 12:53:49.165296\n",
      "Evaluating TF-IDF SVM at 2020-11-22 13:01:16.730051\n",
      "('tfidf', 1.0, 1, False, 403015, 0.572992892212361, 0.5728954083306359, 0.40474073419525153, 0.4046529784400566)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 1.0 min_df = 3 lower = True\n",
      "Count vectorizing at 2020-11-22 13:01:27.576179\n",
      "TF-IDF vectorizing at 2020-11-22 13:01:46.428601\n",
      "Fitting TF-IDF count SVM at 2020-11-22 13:01:47.622652\n",
      "Evaluating TF-IDF SVM at 2020-11-22 13:07:08.220482\n",
      "('tfidf', 1.0, 3, True, 89225, 0.5095888860047827, 0.5094016755142587, 0.4028132921703881, 0.4025821349710565)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 1.0 min_df = 3 lower = False\n",
      "Count vectorizing at 2020-11-22 13:07:19.941683\n",
      "TF-IDF vectorizing at 2020-11-22 13:07:39.325894\n",
      "Fitting TF-IDF count SVM at 2020-11-22 13:07:40.589985\n",
      "Evaluating TF-IDF SVM at 2020-11-22 13:13:23.970667\n",
      "('tfidf', 1.0, 3, False, 113168, 0.5251050704427593, 0.5249618932081128, 0.40431548194334754, 0.40416405698775665)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 1.0 min_df = 5 lower = True\n",
      "Count vectorizing at 2020-11-22 13:13:34.516729\n",
      "TF-IDF vectorizing at 2020-11-22 13:13:52.457451\n",
      "Fitting TF-IDF count SVM at 2020-11-22 13:13:53.590186\n",
      "Evaluating TF-IDF SVM at 2020-11-22 13:18:47.078621\n",
      "('tfidf', 1.0, 5, True, 62986, 0.498118120716412, 0.4979021818259892, 0.4026862687704687, 0.4024082001431919)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 1.0 min_df = 5 lower = False\n",
      "Count vectorizing at 2020-11-22 13:18:57.580805\n",
      "TF-IDF vectorizing at 2020-11-22 13:19:16.576168\n",
      "Fitting TF-IDF count SVM at 2020-11-22 13:19:17.861719\n",
      "Evaluating TF-IDF SVM at 2020-11-22 13:24:10.618107\n",
      "('tfidf', 1.0, 5, False, 79026, 0.5113685942927834, 0.5112075669720698, 0.40380738834367014, 0.40362840594475013)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 0.1 min_df = 1 lower = True\n",
      "Count vectorizing at 2020-11-22 13:24:21.066587\n",
      "TF-IDF vectorizing at 2020-11-22 13:24:40.342114\n",
      "Fitting TF-IDF count SVM at 2020-11-22 13:24:41.609599\n",
      "Evaluating TF-IDF SVM at 2020-11-22 13:30:26.261744\n",
      "('tfidf', 0.1, 1, True, 314425, 0.5541271559460758, 0.5540270389111172, 0.4038902296914436, 0.403710770910402)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 0.1 min_df = 1 lower = False\n",
      "Count vectorizing at 2020-11-22 13:30:36.917284\n",
      "TF-IDF vectorizing at 2020-11-22 13:30:55.656553\n",
      "Fitting TF-IDF count SVM at 2020-11-22 13:30:57.044005\n",
      "Evaluating TF-IDF SVM at 2020-11-22 13:37:44.429603\n",
      "('tfidf', 0.1, 1, False, 402993, 0.5758688676692311, 0.5757887724141555, 0.40403934411743586, 0.4040103398733456)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 0.1 min_df = 3 lower = True\n",
      "Count vectorizing at 2020-11-22 13:37:56.350983\n",
      "TF-IDF vectorizing at 2020-11-22 13:38:15.126870\n",
      "Fitting TF-IDF count SVM at 2020-11-22 13:38:16.085482\n",
      "Evaluating TF-IDF SVM at 2020-11-22 13:43:01.144838\n",
      "('tfidf', 0.1, 3, True, 89202, 0.5102916567717279, 0.5101216166778023, 0.40255372261403105, 0.4023184291442446)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 0.1 min_df = 3 lower = False\n",
      "Count vectorizing at 2020-11-22 13:43:11.936578\n",
      "TF-IDF vectorizing at 2020-11-22 13:43:31.059761\n",
      "Fitting TF-IDF count SVM at 2020-11-22 13:43:32.070731\n",
      "Evaluating TF-IDF SVM at 2020-11-22 13:48:22.052100\n",
      "('tfidf', 0.1, 3, False, 113146, 0.525875494977053, 0.5257568239493552, 0.40391784347403475, 0.4037902530139279)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 0.1 min_df = 5 lower = True\n",
      "Count vectorizing at 2020-11-22 13:48:37.932730\n",
      "TF-IDF vectorizing at 2020-11-22 13:49:07.020455\n",
      "Fitting TF-IDF count SVM at 2020-11-22 13:49:08.253672\n",
      "Evaluating TF-IDF SVM at 2020-11-22 13:54:10.863722\n",
      "('tfidf', 0.1, 5, True, 62963, 0.4983625026923438, 0.4981593213535958, 0.4019738331796166, 0.401674316929647)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 0.1 min_df = 5 lower = False\n",
      "Count vectorizing at 2020-11-22 13:54:21.507404\n",
      "TF-IDF vectorizing at 2020-11-22 13:54:40.138946\n",
      "Fitting TF-IDF count SVM at 2020-11-22 13:54:41.088563\n",
      "Evaluating TF-IDF SVM at 2020-11-22 13:59:25.180438\n",
      "('tfidf', 0.1, 5, False, 79004, 0.5120975981531902, 0.511961712927674, 0.4029900203789715, 0.4028374082499358)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 0.01 min_df = 1 lower = True\n",
      "Count vectorizing at 2020-11-22 13:59:35.583881\n",
      "TF-IDF vectorizing at 2020-11-22 13:59:53.808785\n",
      "Fitting TF-IDF count SVM at 2020-11-22 13:59:54.650038\n",
      "Evaluating TF-IDF SVM at 2020-11-22 14:05:23.557110\n",
      "('tfidf', 0.01, 1, True, 314181, 0.5608400664939884, 0.5607310772338596, 0.3997923443549144, 0.39965182587089787)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 0.01 min_df = 1 lower = False\n",
      "Count vectorizing at 2020-11-22 14:05:34.871553\n",
      "TF-IDF vectorizing at 2020-11-22 14:05:55.282987\n",
      "Fitting TF-IDF count SVM at 2020-11-22 14:05:56.481847\n",
      "Evaluating TF-IDF SVM at 2020-11-22 14:11:27.007939\n",
      "('tfidf', 0.01, 1, False, 402745, 0.5837871198272482, 0.5837169420883771, 0.40062628058916766, 0.40064107903108725)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 0.01 min_df = 3 lower = True\n",
      "Count vectorizing at 2020-11-22 14:11:38.300809\n",
      "TF-IDF vectorizing at 2020-11-22 14:11:58.847338\n",
      "Fitting TF-IDF count SVM at 2020-11-22 14:11:59.459089\n",
      "Evaluating TF-IDF SVM at 2020-11-22 14:15:28.052507\n",
      "('tfidf', 0.01, 3, True, 88958, 0.5112098150428842, 0.5110101030195807, 0.3990302039553983, 0.3987828468987502)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 0.01 min_df = 3 lower = False\n",
      "Count vectorizing at 2020-11-22 14:15:39.485133\n",
      "TF-IDF vectorizing at 2020-11-22 14:15:59.163710\n",
      "Fitting TF-IDF count SVM at 2020-11-22 14:15:59.860859\n",
      "Evaluating TF-IDF SVM at 2020-11-22 14:18:58.199364\n",
      "('tfidf', 0.01, 3, False, 112898, 0.527651061197665, 0.5275522751016428, 0.3994885927464116, 0.3993915090773104)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 0.01 min_df = 5 lower = True\n",
      "Count vectorizing at 2020-11-22 14:19:09.238194\n",
      "TF-IDF vectorizing at 2020-11-22 14:19:27.725420\n",
      "Fitting TF-IDF count SVM at 2020-11-22 14:19:28.272205\n",
      "Evaluating TF-IDF SVM at 2020-11-22 14:22:26.257775\n",
      "('tfidf', 0.01, 5, True, 62719, 0.4980974103794686, 0.4978667129353074, 0.3988148164511871, 0.3985159849178747)\n",
      "--------------------------------------------------------\n",
      "Working on: max_df = 0.01 min_df = 5 lower = False\n",
      "Count vectorizing at 2020-11-22 14:22:37.266195\n",
      "TF-IDF vectorizing at 2020-11-22 14:22:56.225207\n",
      "Fitting TF-IDF count SVM at 2020-11-22 14:22:56.870595\n",
      "Evaluating TF-IDF SVM at 2020-11-22 14:26:30.988571\n",
      "('tfidf', 0.01, 5, False, 78756, 0.512861119241836, 0.5127324441720106, 0.39923454594657287, 0.3991163170718491)\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test combinations of: min_df, max_df, lower for tokenizer\n",
    "results = []\n",
    "for max_df in [1.0, .1, .01]:\n",
    "    for min_df in [1, 3, 5]:\n",
    "        for lower in [True, False]:\n",
    "            print(\"Working on: max_df = \" + str(max_df) + \" min_df = \" + str(min_df) + \" lower = \" + str(lower))\n",
    "            # raw counts\n",
    "            # to print time: https://www.geeksforgeeks.org/get-current-date-and-time-using-python/\n",
    "            print(\"Count vectorizing at \" + str(datetime.datetime.now()))\n",
    "            cv = CountVectorizer(max_df = max_df, min_df = min_df, lowercase = lower)\n",
    "            X_train_counts = cv.fit_transform(X_train)\n",
    "            X_test_counts = cv.transform(X_test)\n",
    "            # record vocab size for tracking\n",
    "            vocab_size = X_train_counts.shape[1]\n",
    "            # tf-idf version\n",
    "            print(\"TF-IDF vectorizing at \" + str(datetime.datetime.now()))\n",
    "            tv = TfidfTransformer()\n",
    "            X_train_tfidf = tv.fit_transform(X_train_counts)\n",
    "            X_test_tfidf = tv.transform(X_test_counts)\n",
    "\n",
    "\n",
    "            # fit logistic regression on tf-idf version\n",
    "            print(\"Fitting TF-IDF count model at \" + str(datetime.datetime.now()))\n",
    "            model = LogisticRegression(random_state = 771, max_iter = 1000)\n",
    "            model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "            # evaluate \n",
    "            print(\"Evaluating TF-IDF model at \" + str(datetime.datetime.now()))\n",
    "            tf_y_train_pred = model.predict(X_train_tfidf)\n",
    "            tf_y_test_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "            tf_train_f1_micro = f1_score(y_train, tf_y_train_pred, average = 'micro')\n",
    "            tf_train_f1_macro = f1_score(y_train, tf_y_train_pred, average = 'macro')\n",
    "\n",
    "            tf_test_f1_micro = f1_score(y_test, tf_y_test_pred, average = 'micro')\n",
    "            tf_test_f1_macro = f1_score(y_test, tf_y_test_pred, average = 'macro')\n",
    "\n",
    "            # record\n",
    "            curr_tfidf_results = (\"tfidf\", max_df, min_df, lower, vocab_size, tf_train_f1_micro, \n",
    "                            tf_train_f1_macro, tf_test_f1_micro, tf_test_f1_macro)\n",
    "            print(curr_tfidf_results)\n",
    "            results.append(curr_tfidf_results)\n",
    "            print(\"--------------------------------------------------------\")\n",
    "                \n",
    "                \n",
    "full_results = pd.DataFrame(results, columns = [\"type\", \"max_df\", \"min_df\", \"lower\", \"vocab_size\",\n",
    "                                               \"train_micro_f1\", \"train_macro_f1\", \"test_micro_f1\", \"test_macro_f1\"])\n",
    "full_results.to_csv(\"../models/logistic_results.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results['of'] = full_results['train_micro_f1'] - full_results['test_micro_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>max_df</th>\n",
       "      <th>min_df</th>\n",
       "      <th>lower</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>train_micro_f1</th>\n",
       "      <th>train_macro_f1</th>\n",
       "      <th>test_micro_f1</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>402745</td>\n",
       "      <td>0.583787</td>\n",
       "      <td>0.583717</td>\n",
       "      <td>0.400626</td>\n",
       "      <td>0.400641</td>\n",
       "      <td>0.183161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>402993</td>\n",
       "      <td>0.575869</td>\n",
       "      <td>0.575789</td>\n",
       "      <td>0.404039</td>\n",
       "      <td>0.404010</td>\n",
       "      <td>0.171830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>403015</td>\n",
       "      <td>0.572993</td>\n",
       "      <td>0.572895</td>\n",
       "      <td>0.404741</td>\n",
       "      <td>0.404653</td>\n",
       "      <td>0.168252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>314181</td>\n",
       "      <td>0.560840</td>\n",
       "      <td>0.560731</td>\n",
       "      <td>0.399792</td>\n",
       "      <td>0.399652</td>\n",
       "      <td>0.161048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>314425</td>\n",
       "      <td>0.554127</td>\n",
       "      <td>0.554027</td>\n",
       "      <td>0.403890</td>\n",
       "      <td>0.403711</td>\n",
       "      <td>0.150237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>314448</td>\n",
       "      <td>0.551373</td>\n",
       "      <td>0.551251</td>\n",
       "      <td>0.404084</td>\n",
       "      <td>0.403879</td>\n",
       "      <td>0.147289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>112898</td>\n",
       "      <td>0.527651</td>\n",
       "      <td>0.527552</td>\n",
       "      <td>0.399489</td>\n",
       "      <td>0.399392</td>\n",
       "      <td>0.128162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>113146</td>\n",
       "      <td>0.525875</td>\n",
       "      <td>0.525757</td>\n",
       "      <td>0.403918</td>\n",
       "      <td>0.403790</td>\n",
       "      <td>0.121958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>113168</td>\n",
       "      <td>0.525105</td>\n",
       "      <td>0.524962</td>\n",
       "      <td>0.404315</td>\n",
       "      <td>0.404164</td>\n",
       "      <td>0.120790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>78756</td>\n",
       "      <td>0.512861</td>\n",
       "      <td>0.512732</td>\n",
       "      <td>0.399235</td>\n",
       "      <td>0.399116</td>\n",
       "      <td>0.113627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>88958</td>\n",
       "      <td>0.511210</td>\n",
       "      <td>0.511010</td>\n",
       "      <td>0.399030</td>\n",
       "      <td>0.398783</td>\n",
       "      <td>0.112180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>79004</td>\n",
       "      <td>0.512098</td>\n",
       "      <td>0.511962</td>\n",
       "      <td>0.402990</td>\n",
       "      <td>0.402837</td>\n",
       "      <td>0.109108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>89202</td>\n",
       "      <td>0.510292</td>\n",
       "      <td>0.510122</td>\n",
       "      <td>0.402554</td>\n",
       "      <td>0.402318</td>\n",
       "      <td>0.107738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>79026</td>\n",
       "      <td>0.511369</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.403807</td>\n",
       "      <td>0.403628</td>\n",
       "      <td>0.107561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>89225</td>\n",
       "      <td>0.509589</td>\n",
       "      <td>0.509402</td>\n",
       "      <td>0.402813</td>\n",
       "      <td>0.402582</td>\n",
       "      <td>0.106776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>62719</td>\n",
       "      <td>0.498097</td>\n",
       "      <td>0.497867</td>\n",
       "      <td>0.398815</td>\n",
       "      <td>0.398516</td>\n",
       "      <td>0.099283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>62963</td>\n",
       "      <td>0.498363</td>\n",
       "      <td>0.498159</td>\n",
       "      <td>0.401974</td>\n",
       "      <td>0.401674</td>\n",
       "      <td>0.096389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>62986</td>\n",
       "      <td>0.498118</td>\n",
       "      <td>0.497902</td>\n",
       "      <td>0.402686</td>\n",
       "      <td>0.402408</td>\n",
       "      <td>0.095432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     type  max_df  min_df  lower  vocab_size  train_micro_f1  train_macro_f1  \\\n",
       "13  tfidf    0.01       1  False      402745        0.583787        0.583717   \n",
       "7   tfidf    0.10       1  False      402993        0.575869        0.575789   \n",
       "1   tfidf    1.00       1  False      403015        0.572993        0.572895   \n",
       "12  tfidf    0.01       1   True      314181        0.560840        0.560731   \n",
       "6   tfidf    0.10       1   True      314425        0.554127        0.554027   \n",
       "0   tfidf    1.00       1   True      314448        0.551373        0.551251   \n",
       "15  tfidf    0.01       3  False      112898        0.527651        0.527552   \n",
       "9   tfidf    0.10       3  False      113146        0.525875        0.525757   \n",
       "3   tfidf    1.00       3  False      113168        0.525105        0.524962   \n",
       "17  tfidf    0.01       5  False       78756        0.512861        0.512732   \n",
       "14  tfidf    0.01       3   True       88958        0.511210        0.511010   \n",
       "11  tfidf    0.10       5  False       79004        0.512098        0.511962   \n",
       "8   tfidf    0.10       3   True       89202        0.510292        0.510122   \n",
       "5   tfidf    1.00       5  False       79026        0.511369        0.511208   \n",
       "2   tfidf    1.00       3   True       89225        0.509589        0.509402   \n",
       "16  tfidf    0.01       5   True       62719        0.498097        0.497867   \n",
       "10  tfidf    0.10       5   True       62963        0.498363        0.498159   \n",
       "4   tfidf    1.00       5   True       62986        0.498118        0.497902   \n",
       "\n",
       "    test_micro_f1  test_macro_f1        of  \n",
       "13       0.400626       0.400641  0.183161  \n",
       "7        0.404039       0.404010  0.171830  \n",
       "1        0.404741       0.404653  0.168252  \n",
       "12       0.399792       0.399652  0.161048  \n",
       "6        0.403890       0.403711  0.150237  \n",
       "0        0.404084       0.403879  0.147289  \n",
       "15       0.399489       0.399392  0.128162  \n",
       "9        0.403918       0.403790  0.121958  \n",
       "3        0.404315       0.404164  0.120790  \n",
       "17       0.399235       0.399116  0.113627  \n",
       "14       0.399030       0.398783  0.112180  \n",
       "11       0.402990       0.402837  0.109108  \n",
       "8        0.402554       0.402318  0.107738  \n",
       "5        0.403807       0.403628  0.107561  \n",
       "2        0.402813       0.402582  0.106776  \n",
       "16       0.398815       0.398516  0.099283  \n",
       "10       0.401974       0.401674  0.096389  \n",
       "4        0.402686       0.402408  0.095432  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results.sort_values(by = \"of\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vectorizing at 2020-11-22 18:12:16.869536\n",
      "Fitting TF-IDF count model at 2020-11-22 18:12:18.981698\n",
      "Evaluating TF-IDF model at 2020-11-22 18:20:08.319788\n"
     ]
    }
   ],
   "source": [
    "# best params are 1.0, 1, false\n",
    "cv = CountVectorizer(max_df = 1.0, min_df = 1, lowercase = False)\n",
    "X_train_counts = cv.fit_transform(X_train)\n",
    "X_test_counts = cv.transform(X_test)\n",
    "\n",
    "# tf-idf version\n",
    "print(\"TF-IDF vectorizing at \" + str(datetime.datetime.now()))\n",
    "tv = TfidfTransformer()\n",
    "X_train_tfidf = tv.fit_transform(X_train_counts)\n",
    "X_test_tfidf = tv.transform(X_test_counts)\n",
    "\n",
    "\n",
    "# fit logistic regression on tf-idf version\n",
    "print(\"Fitting TF-IDF count model at \" + str(datetime.datetime.now()))\n",
    "model = LogisticRegression(random_state = 771, max_iter = 1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# evaluate \n",
    "print(\"Evaluating TF-IDF model at \" + str(datetime.datetime.now()))\n",
    "tf_y_train_pred = model.predict(X_train_tfidf)\n",
    "tf_y_test_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "tf_train_f1_micro = f1_score(y_train, tf_y_train_pred, average = 'micro')\n",
    "tf_train_f1_macro = f1_score(y_train, tf_y_train_pred, average = 'macro')\n",
    "\n",
    "tf_test_f1_micro = f1_score(y_test, tf_y_test_pred, average = 'micro')\n",
    "tf_test_f1_macro = f1_score(y_test, tf_y_test_pred, average = 'macro')\n",
    "\n",
    "with open('../models/best_logistic.p', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/logistic_cv.p', 'wb') as f:\n",
    "    pickle.dump(cv, f) \n",
    "\n",
    "with open('../models/logistic_tfidf.p', 'wb') as f:\n",
    "    pickle.dump(tv, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at accuracy by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_class = pd.DataFrame()\n",
    "by_class[\"pred\"] = tf_y_test_pred\n",
    "by_class[\"true\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_class[\"correct\"] = by_class[\"pred\"] == by_class[\"true\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true           correct\n",
       "bad            False      55.153074\n",
       "               True       44.846926\n",
       "controversial  False      65.569661\n",
       "               True       34.430339\n",
       "good           False      57.604056\n",
       "               True       42.395944\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/23377108/pandas-percentage-of-total-with-groupby\n",
    "by_class.groupby([\"true\", \"correct\"]).size().groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on the BERT test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_test = pd.read_csv(\"../data/final_eval_set.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_test.rename(columns = {'pred':'bert_pred', 'match':'bert_match'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert_pred</th>\n",
       "      <th>true</th>\n",
       "      <th>text</th>\n",
       "      <th>bert_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>One nickname for the city of Columbus, Ohio. C...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-adjective ;; used to denote an ignorant or fo...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>someone that is really stupid.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasty pieces of poopoo that just will not come...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A hardedend clump of fecal matter attached to ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bert_pred  true                                               text  \\\n",
       "0          0     0  One nickname for the city of Columbus, Ohio. C...   \n",
       "1          1     1  -adjective ;; used to denote an ignorant or fo...   \n",
       "2          2     0                     someone that is really stupid.   \n",
       "3          2     2  Nasty pieces of poopoo that just will not come...   \n",
       "4          0     2  A hardedend clump of fecal matter attached to ...   \n",
       "\n",
       "   bert_match  \n",
       "0        True  \n",
       "1        True  \n",
       "2       False  \n",
       "3        True  \n",
       "4       False  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cats = {\"good\": 0, \"controversial\": 1, \"bad\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bert_test = tv.transform(cv.transform(bert_test['text']))\n",
    "y_pred_bert_test = model.predict(X_bert_test)\n",
    "bert_test['log_pred'] = pd.Series(y_pred_bert_test).map(int_cats)\n",
    "bert_test['log_match'] = bert_test['log_pred'] == bert_test['true']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_match\n",
       "False    0.6\n",
       "True     0.4\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_test.groupby('log_match').size().transform(lambda x: round(x/sum(x),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert_pred</th>\n",
       "      <th>true</th>\n",
       "      <th>text</th>\n",
       "      <th>bert_match</th>\n",
       "      <th>log_pred</th>\n",
       "      <th>log_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>One nickname for the city of Columbus, Ohio. C...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-adjective ;; used to denote an ignorant or fo...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>someone that is really stupid.</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasty pieces of poopoo that just will not come...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A hardedend clump of fecal matter attached to ...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bert_pred  true                                               text  \\\n",
       "0          0     0  One nickname for the city of Columbus, Ohio. C...   \n",
       "1          1     1  -adjective ;; used to denote an ignorant or fo...   \n",
       "2          2     0                     someone that is really stupid.   \n",
       "3          2     2  Nasty pieces of poopoo that just will not come...   \n",
       "4          0     2  A hardedend clump of fecal matter attached to ...   \n",
       "\n",
       "   bert_match  log_pred  log_match  \n",
       "0        True         1      False  \n",
       "1        True         1       True  \n",
       "2       False         2      False  \n",
       "3        True         2       True  \n",
       "4       False         2       True  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_test.to_csv(\"../data/final_eval_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bad', 'controversial', 'controversial', ..., 'controversial',\n",
       "       'good', 'bad'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_ex(text, count_vectorizer, tfidf_vectorizer, model):\n",
    "    text = tfidf_vectorizer.transform(count_vectorizer.transform([text]))\n",
    "    pred = model.predict(text)\n",
    "    print(pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "bad\n",
      "bad\n",
      "controversial\n",
      "bad\n"
     ]
    }
   ],
   "source": [
    "pred_ex(\"this could be a very good definition\", cv, tv, svm_tf)\n",
    "pred_ex(\"nonsense nonsense yada yada\", cv, tv, svm_tf)\n",
    "pred_ex(\"this is an example of a definition with interesting words and content like a car and a house\", cv, tv, svm_tf)\n",
    "pred_ex(\"merrily we roll along\", cv, tv, svm_tf)\n",
    "pred_ex(\"rudolph the red-nosed reindeer had a very shiny nose\", cv, tv, svm_tf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
