{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 503,
     "status": "ok",
     "timestamp": 1606166870476,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "9AHc8DjMLRgb"
   },
   "outputs": [],
   "source": [
    "# code ultimately from: https://huggingface.co/transformers/custom_datasets.html\n",
    "\n",
    "\n",
    "# articles I read but didn't end up using as much\n",
    "# https://towardsdatascience.com/bert-to-the-rescue-17671379687f\n",
    "# https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613\n",
    "# https://towardsdatascience.com/bert-text-classification-using-pytorch-723dfb8b6b5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1009,
     "status": "ok",
     "timestamp": 1606166870988,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "bK5mompFKy35",
    "outputId": "61d0644b-db97-4496-d5f5-67ff897909b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3603,
     "status": "ok",
     "timestamp": 1606166873589,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "7P3-fTuNIfmH",
    "outputId": "1003aa14-46d0-424c-d68b-548dd47709b9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n",
      "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6067,
     "status": "ok",
     "timestamp": 1606166876061,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "pursAxTiLD90"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import torch\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments, AdamW\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6062,
     "status": "ok",
     "timestamp": 1606166876061,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "pVFIy019MNnx",
    "outputId": "b4220ff5-12fe-460d-9718-8bcd18887d55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# check that we're using GPU - this is from the Chen notebook: https://colab.research.google.com/drive/1P4Hq0btDUDOTGkCHGzZbAx1lb0bTzMMa?usp=sharing\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6055,
     "status": "ok",
     "timestamp": 1606166876062,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "5WzucvQq8JoF"
   },
   "outputs": [],
   "source": [
    "# set all seeds: https://github.com/shudima/notebooks/blob/master/BERT_to_the_rescue.ipynb\n",
    "rn.seed(117)\n",
    "np.random.seed(117)\n",
    "torch.manual_seed(117)\n",
    "torch.cuda.manual_seed(117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 8175,
     "status": "ok",
     "timestamp": 1606166878186,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "z3zHX7USRRn5"
   },
   "outputs": [],
   "source": [
    "# load train, val, test\n",
    "data_path = \"/content/drive/MyDrive/nlp_data/deep_learning_data/\"\n",
    "train = pd.read_csv(data_path + \"train.csv\")\n",
    "test = pd.read_csv(data_path + \"test.csv\")\n",
    "val = pd.read_csv(data_path + \"val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 8171,
     "status": "ok",
     "timestamp": 1606166878187,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "AK-xXGS3lS6i"
   },
   "outputs": [],
   "source": [
    "# truncate to lengths that Colab RAM can handle\n",
    "train_texts = train['defn'][0:50000]\n",
    "train_labels = train['cat'][0:50000]\n",
    "\n",
    "val_texts = val['defn'][0:12500]\n",
    "val_labels = val['cat'][0:12500]\n",
    "\n",
    "test_texts = test['defn'][0:12500]\n",
    "test_labels = test['cat'][0:12500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 16608,
     "status": "ok",
     "timestamp": 1606166886629,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "nQutoeMaLdO_"
   },
   "outputs": [],
   "source": [
    "# instantiate BERT tokenizer and tokenize the data\n",
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 16602,
     "status": "ok",
     "timestamp": 1606166886630,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "3UgqV-KC8tdX"
   },
   "outputs": [],
   "source": [
    "# make a torch Dataset for the data\n",
    "class UDDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = UDDataset(train_encodings, train_labels)\n",
    "val_dataset = UDDataset(val_encodings, val_labels)\n",
    "test_dataset = UDDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 831
    },
    "id": "3ReIGqp1D0cW",
    "outputId": "6fee7145-7def-4cfb-fb24-e2395093d1e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='10589' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10589/18750 24:43 < 19:03, 7.14 it/s, Epoch 1.69/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.100668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.095058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.085775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.088925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.091675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.088419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.082031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.081734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.088106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.081945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.075980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.082274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.068282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.043704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.027735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.039795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.036742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.040787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.026373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.031986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.038521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute metrics is from: https://huggingface.co/transformers/training.html\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/content/drive/MyDrive/nlp_data/bert_results2/final_model/checkpoints',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='/content/drive/MyDrive/nlp_data/bert_results2/final_model/logs/',            # directory for storing logs\n",
    "    logging_steps=500,               #adjusted these steps to take less memory\n",
    "    save_steps = 2500,\n",
    "    save_total_limit = 10,\n",
    ")\n",
    "\n",
    "# must tell the model how many labels to expect, else assumes binary\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = 3)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics = compute_metrics)             \n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1985,
     "status": "ok",
     "timestamp": 1606170504368,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "kKdWMaOgL-A6",
    "outputId": "4b76b742-0e28-4ff1-8fa3-97701e8d3008"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/nlp_data/bert_results2/final_model/tokenizer/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/nlp_data/bert_results2/final_model/tokenizer/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/nlp_data/bert_results2/final_model/tokenizer/vocab.txt',\n",
       " '/content/drive/MyDrive/nlp_data/bert_results2/final_model/tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the final model and tokenizer for reuse\n",
    "trainer.save_model('/content/drive/MyDrive/nlp_data/bert_results2/final_model/model')\n",
    "tokenizer.save_pretrained('/content/drive/MyDrive/nlp_data/bert_results2/final_model/tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 56925,
     "status": "ok",
     "timestamp": 1606170724269,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "FPxFVWn_OwVe",
    "outputId": "b6ad39b0-5d84-4f1b-c4f3-8ff490c2f44a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='2346' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 20:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_eval2 = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 223874,
     "status": "ok",
     "timestamp": 1606171482814,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "rOfXx8UhRCrJ",
    "outputId": "a9be987c-6b14-4bee-ed97-562473285c2e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='5471' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 32:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_eval = trainer.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 916,
     "status": "ok",
     "timestamp": 1606171547811,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "HWwXmz4jRJyV",
    "outputId": "a7448e16-a694-42a0-e1e2-5f464bb8fc32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.672,\n",
       " 'eval_f1': 0.672,\n",
       " 'eval_loss': 0.7674375176429749,\n",
       " 'eval_precision': 0.672,\n",
       " 'eval_recall': 0.672}"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics on train set\n",
    "train_eval.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 850,
     "status": "ok",
     "timestamp": 1606170854318,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "bEZemgvLPiUc",
    "outputId": "1cdf77f5-0399-4ef7-aa67-90ea67fab201"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.40144,\n",
       " 'eval_f1': 0.40143999999999996,\n",
       " 'eval_loss': 1.2062667608261108,\n",
       " 'eval_precision': 0.40144,\n",
       " 'eval_recall': 0.40144}"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics on test set\n",
    "test_eval2.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1606170749418,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "DPpIDxetQCpA"
   },
   "outputs": [],
   "source": [
    "# now we save out the results on the test set for comparison with other models\n",
    "pred = test_eval2.predictions.argmax(-1)\n",
    "results = pd.DataFrame({\"pred\": pred, \"true\": test_labels, \"text\" : test_texts})\n",
    "results[\"match\"] = results[\"pred\"] == results[\"true\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1606170814005,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "lgNah1Qypdwj",
    "outputId": "ac6e45e8-3f6b-4b7b-d098-f9b9c1f5872b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true  match\n",
       "0     False    56.138614\n",
       "      True     43.861386\n",
       "1     False    55.308924\n",
       "      True     44.691076\n",
       "2     False    68.386308\n",
       "      True     31.613692\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how the model performs by true category\n",
    "results.groupby([\"true\", \"match\"]).size().groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 852,
     "status": "ok",
     "timestamp": 1606171653990,
     "user": {
      "displayName": "Laurie Merrell",
      "photoUrl": "https://lh3.googleusercontent.com/-g3du-kbAnsQ/AAAAAAAAAAI/AAAAAAAABos/6M8wF7b5Q2k/s64/photo.jpg",
      "userId": "11231051729815913464"
     },
     "user_tz": 360
    },
    "id": "S6gGMt527Zvx"
   },
   "outputs": [],
   "source": [
    "# save test results\n",
    "results.to_csv(\"/content/drive/MyDrive/nlp_data/bert_results2/final_model/test_eval_final_bert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjxfkfxgroU3"
   },
   "outputs": [],
   "source": [
    "# example of loading a previously-trained model \n",
    "# original_model = DistilBertForSequenceClassification.from_pretrained('/content/drive/MyDrive/nlp_data/bert_results2/first_batch', num_labels = 3)\n",
    "\n",
    "# prediction syntax: https://github.com/huggingface/transformers\n",
    "# https://stackoverflow.com/questions/55466298/pytorch-cant-call-numpy-on-variable-that-requires-grad-use-var-detach-num\n",
    "\n",
    "# inputs = tokenizer(list(test_texts)[1:100], truncation = True, padding = True, return_tensors=\"pt\")\n",
    "# outputs = original_model(**inputs)\n",
    "\n",
    "# outputs[0].detach().numpy().argmax(-1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMi5M0Z6WRPsX+2x9TsapaL",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BERT_model2.ipynb",
   "provenance": [
    {
     "file_id": "1FQG7eQPB6K7xHm3BIcJaRyd3W5m5d_o0",
     "timestamp": 1606108468345
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
